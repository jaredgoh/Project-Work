# Data Reconciliation Tool

Our company had consistent data quality issues that were not addressed in a timely manner. Often this compromised various analysis done and models built.
  
The purpose of this tool was to ensure our data quality issues were easily identified and addressed regularly. In particular, to ensure that the data is complete, consistent, accurate, unique, timely and valid.

Furthermore, it was necessary to produce a csv in a specific format in order to feed the checks done into our dashboards for visibility accross the company and a detailed report for us to be able to investigate the issues quickly and identify the likely causes. 
Since we started using this tool, our average monthly errors went down from about 10% - 15% to about 2% - 5% and the average time the team spends per month on checking and investigating data errors went down about 20% (from about 48 man-hours to about 38 man-hours per month). Most importantly, our average time taken for detection and response to errors went down significantly from about 3-4 weeks to 3-7 days. 

I have included a sample output to demonstrate what the tool is supposed to produce. Please note that the values in these outputs have been changed.


	

